{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "张量进阶操作.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOG2DizvhPVMC5GX4DlMXMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZinoTAT/Machine-Learning-Practices/blob/master/pytorch/%E5%BC%A0%E9%87%8F%E8%BF%9B%E9%98%B6%E6%93%8D%E4%BD%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFxXw_5-1bO",
        "colab_type": "code",
        "outputId": "53627814-ea42-4445-87cb-df5f0fb557b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leQ3ZdLK_E_P",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzrusH9B_G5M",
        "colab_type": "text"
      },
      "source": [
        "# 张量的扩张"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcEHv_2_V1jT",
        "colab_type": "text"
      },
      "source": [
        "## broadcast-免拷贝的自动扩展\n",
        "当参与运算的量张量尺寸不一致时，一般会自动进行broadcast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0xuLBq2EJs7",
        "colab_type": "code",
        "outputId": "820d56e7-b180-4914-8121-a71e2b0233c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "x = torch.tensor([1, 2])\n",
        "y = torch.tensor([[-1], [-2]])\n",
        "print(x, y)\n",
        "x1, y1 = torch.broadcast_tensors(x, y)\n",
        "print(x1, y1)\n",
        "print(x + y)\n",
        "print(torch.all(torch.eq((x1 + y1), x + y)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2]) tensor([[-1],\n",
            "        [-2]])\n",
            "tensor([[1, 2],\n",
            "        [1, 2]]) tensor([[-1, -1],\n",
            "        [-2, -2]])\n",
            "tensor([[ 0,  1],\n",
            "        [-1,  0]])\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzvrnFxV29z",
        "colab_type": "text"
      },
      "source": [
        "# 张量的拼接"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNCIQBliUYul",
        "colab_type": "text"
      },
      "source": [
        "## cat-不增加维度的张量拼接\n",
        "torch.cat([tensor1, tensor2], dim=index)\\\n",
        "将张量进行拼接，除选择拼接的维度外其他维度必须保持一致"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmtXcvnhUrpm",
        "colab_type": "code",
        "outputId": "0d15b267-37ca-44de-f4cb-1d1cff614702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.rand(4, 3, 32, 32)\n",
        "y = torch.rand(5, 3, 32, 32)\n",
        "print(torch.cat([x, y], dim=0).shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([9, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdUuXbEZV-i5",
        "colab_type": "text"
      },
      "source": [
        "## stack-增加维度的张量拼接\n",
        "torch.stack([tensor1, tensor2], dim=index) \\\n",
        "进行拼接的两张量必须尺寸必须相同，拼接后在指定位置增加新的维度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nNtRv0aWZCk",
        "colab_type": "code",
        "outputId": "c190eacc-9e27-4167-fb18-e100bcfa51ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.rand(4, 3, 32, 32)\n",
        "y = torch.rand(4, 3, 32, 32)\n",
        "print(torch.stack([x, y], dim=0).shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esLzB6NTYOHT",
        "colab_type": "text"
      },
      "source": [
        "# 张量的拆分"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqA1y3mCYRR5",
        "colab_type": "text"
      },
      "source": [
        "## split-指定长度的拆分\n",
        "split(step, dim=index)\\\n",
        "指定一个固定长度，按找长度进行拆分\\\n",
        "split(list, dim=index)\\\n",
        "使用一个list指定每一段拆分的长度进行拆分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKz8ixEFYzak",
        "colab_type": "code",
        "outputId": "fa793df3-6e2b-4e4b-ec3e-6a36409f7be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "a = torch.rand(9, 2)\n",
        "print(a.split(3, dim=0))\n",
        "print(a.split([2, 3, 4], dim=0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0.2808, 0.5702],\n",
            "        [0.6199, 0.6343],\n",
            "        [0.5571, 0.7155]]), tensor([[0.1591, 0.7327],\n",
            "        [0.5245, 0.5961],\n",
            "        [0.5282, 0.4291]]), tensor([[0.8591, 0.2267],\n",
            "        [0.7825, 0.7314],\n",
            "        [0.8931, 0.3310]]))\n",
            "(tensor([[0.2808, 0.5702],\n",
            "        [0.6199, 0.6343]]), tensor([[0.5571, 0.7155],\n",
            "        [0.1591, 0.7327],\n",
            "        [0.5245, 0.5961]]), tensor([[0.5282, 0.4291],\n",
            "        [0.8591, 0.2267],\n",
            "        [0.7825, 0.7314],\n",
            "        [0.8931, 0.3310]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCHCYeEoYyuK",
        "colab_type": "text"
      },
      "source": [
        "## chunk-指定个数的拆分\n",
        "chunk(num, dim=index)\\\n",
        "对指定维度拆分成num个新的张量\\\n",
        "在下面的例子中可以看到，当对长度为9的维度进行拆分，指定的拆分个数为4个时，拆分的结果为3个长度为3的张量，而非4个长度和为9的张量，因此我猜测这里拆分的机制应该是以step为单位对长度为len的维度进行拆分，当余下不足step时停止划分，其中step为(len / num)的值向上取整，也就是说：\\\n",
        "chunk(num, dim=index)的结果与split(math.ceil(len / num), dim=index)\\\n",
        "这同时意味着使用chunk划分时划分出的张量个数可能并非我们选择的参数num\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E6gVyB_ahdd",
        "colab_type": "code",
        "outputId": "8d7af831-e4b7-4550-cb7a-6a52db149ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "a = torch.rand(9, 2)\n",
        "print(a.chunk(4, dim=0))\n",
        "print(a.chunk(3, dim=0))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0.2328, 0.7287],\n",
            "        [0.4001, 0.2695],\n",
            "        [0.6390, 0.4735]]), tensor([[0.3969, 0.6350],\n",
            "        [0.2509, 0.2864],\n",
            "        [0.5829, 0.5239]]), tensor([[0.5608, 0.4934],\n",
            "        [0.2795, 0.4223],\n",
            "        [0.7884, 0.3159]]))\n",
            "(tensor([[0.2328, 0.7287],\n",
            "        [0.4001, 0.2695],\n",
            "        [0.6390, 0.4735]]), tensor([[0.3969, 0.6350],\n",
            "        [0.2509, 0.2864],\n",
            "        [0.5829, 0.5239]]), tensor([[0.5608, 0.4934],\n",
            "        [0.2795, 0.4223],\n",
            "        [0.7884, 0.3159]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy50vAtHaguJ",
        "colab_type": "text"
      },
      "source": [
        "# 张量的运算\n",
        "张量的加减运算调用函数方法和使用运算符的结果是一致的，但使用乘号时并不是张量的乘法运算，而是直接将两张量对应位置相乘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0YHiK-sTCQB",
        "colab_type": "text"
      },
      "source": [
        "## 张量的加减\n",
        "张量维度不一致时采用从最后一个维度向前对齐并自动broadcast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi1HskrrTBhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "89df062d-e839-4890-dd76-6f225c4c5cec"
      },
      "source": [
        "a = torch.rand(3, 4)\n",
        "b = torch.rand(4)\n",
        "print(a + b)\n",
        "print(torch.all(torch.eq(a + b, torch.add(a, b))))\n",
        "print(torch.all(torch.eq(a - b, torch.sub(a, b))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2560, 1.6309, 1.2057, 0.5669],\n",
            "        [1.5047, 1.1817, 0.8315, 0.7873],\n",
            "        [1.5891, 1.1047, 1.3399, 0.8395]])\n",
            "tensor(True)\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSq-AIJzW9Dl",
        "colab_type": "text"
      },
      "source": [
        "## matmul-向量的乘法\n",
        "torch.mm可以对两个二维张量进行相乘操作\\\n",
        "torch.matmul可以对不少于二维的张量进行操作，对最后两维做乘法\\\n",
        "matmul等价于运算符@，不等价于运算符*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9q7HR3XzxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "25ce78a5-7c7a-4688-ea0f-c28ebc3306c3"
      },
      "source": [
        "x = torch.rand(1, 2, 3)\n",
        "y = torch.rand(1, 3, 4)\n",
        "print(torch.matmul(x, y).shape)\n",
        "try:\n",
        "  x * y\n",
        "except RuntimeError:\n",
        "  print('failed')\n",
        "print(torch.all(torch.eq(torch.matmul(x, y), x@y)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 4])\n",
            "failed\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxv5Y_QNmn9I",
        "colab_type": "text"
      },
      "source": [
        "## 幂、指数和对数\n",
        "幂操作可以使用pow()函数或这运算符 **\\\n",
        "指数使用torch.exp(),对数使用torch.log()、torch.log2()、torch.log10()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxJnKJNAYuVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "599d40dc-3443-4e0d-9bf0-9b05c360c896"
      },
      "source": [
        "a = torch.full([2, 3], 2)\n",
        "print(a)\n",
        "print(a.pow(2))\n",
        "print(torch.all(torch.eq(a.pow(3), a**3)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ljBDC5n6Me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "9878996e-1189-4954-9dc0-ed58070a0c1d"
      },
      "source": [
        "a = torch.full([2, 3], 3)\n",
        "print(torch.exp(a))\n",
        "print(torch.log(a))\n",
        "print(torch.log2(a))\n",
        "print(torch.log10(a))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[20.0855, 20.0855, 20.0855],\n",
            "        [20.0855, 20.0855, 20.0855]])\n",
            "tensor([[1.0986, 1.0986, 1.0986],\n",
            "        [1.0986, 1.0986, 1.0986]])\n",
            "tensor([[1.5850, 1.5850, 1.5850],\n",
            "        [1.5850, 1.5850, 1.5850]])\n",
            "tensor([[0.4771, 0.4771, 0.4771],\n",
            "        [0.4771, 0.4771, 0.4771]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y962DSxhol74",
        "colab_type": "text"
      },
      "source": [
        "## clamp-张量的reLU操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0vyUnproiqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "448cb56c-110a-4451-acc3-f8a915207d1b"
      },
      "source": [
        "grad = torch.rand(2, 3) * 10\n",
        "print(grad)\n",
        "print(grad.max())\n",
        "print(grad.median())\n",
        "print(grad.clamp(5))\n",
        "print(grad.clamp(5,7))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.5482, 2.0971, 8.6715],\n",
            "        [7.3118, 3.1960, 7.1071]])\n",
            "tensor(8.6715)\n",
            "tensor(3.1960)\n",
            "tensor([[5.0000, 5.0000, 8.6715],\n",
            "        [7.3118, 5.0000, 7.1071]])\n",
            "tensor([[5., 5., 7.],\n",
            "        [7., 5., 7.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlX7ekbJrppz",
        "colab_type": "text"
      },
      "source": [
        "# 张量的属性统计"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwDrWL9wsAE0",
        "colab_type": "text"
      },
      "source": [
        "## norm-范数计算\n",
        "norm(index, dim= )dim可省略"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ymacbNruEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afadf153-07d9-4a8b-9669-654da905620e"
      },
      "source": [
        "a = torch.full([2, 3], 1)\n",
        "print(a.norm(1), a.norm(2), a.norm(2, dim=1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6.) tensor(2.4495) tensor([1.7321, 1.7321])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwOYwSj4sd3W",
        "colab_type": "text"
      },
      "source": [
        "## mean,sum,max,min,prod\n",
        "max(dim=1, keepdim=True)keepdim参数用来选择是否保留原张量维度\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gwm1VBRslNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "57f00441-9a2f-44cb-89ba-155c97e309fe"
      },
      "source": [
        "a = torch.arange(9).reshape(3, 3).float()\n",
        "a = a + 1\n",
        "print(a)\n",
        "print(a.mean(), a.sum(), a.max(dim=0), a.min(), a.prod())\n",
        "print(a.argmax(),a.argmin(dim=1))\n",
        "print(a.max(dim=1, keepdim=True))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "tensor(5.) tensor(45.) torch.return_types.max(\n",
            "values=tensor([7., 8., 9.]),\n",
            "indices=tensor([2, 2, 2])) tensor(1.) tensor(362880.)\n",
            "tensor(8) tensor([0, 0, 0])\n",
            "torch.return_types.max(\n",
            "values=tensor([[3.],\n",
            "        [6.],\n",
            "        [9.]]),\n",
            "indices=tensor([[2],\n",
            "        [2],\n",
            "        [2]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI6enNAi3c9j",
        "colab_type": "text"
      },
      "source": [
        "## topk、k-th\n",
        "topk(k, dim=, largest=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3EA9meE0fIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "26e923f0-bfb3-4d37-f7c5-47c5bc351778"
      },
      "source": [
        "a = torch.arange(12).reshape(3, 4)\n",
        "a = a + 1\n",
        "print(a)\n",
        "print(a.topk(2, dim=1))\n",
        "print(a.topk(2, dim=1, largest=False))\n",
        "print(a.kthvalue(2,dim=1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.return_types.topk(\n",
            "values=tensor([[ 4,  3],\n",
            "        [ 8,  7],\n",
            "        [12, 11]]),\n",
            "indices=tensor([[3, 2],\n",
            "        [3, 2],\n",
            "        [3, 2]]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([[ 1,  2],\n",
            "        [ 5,  6],\n",
            "        [ 9, 10]]),\n",
            "indices=tensor([[0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1]]))\n",
            "torch.return_types.kthvalue(\n",
            "values=tensor([ 2,  6, 10]),\n",
            "indices=tensor([1, 1, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI_Cp6V25qOc",
        "colab_type": "text"
      },
      "source": [
        "# 张量的比较\n",
        "符号与python一致，返回值为mask张量\\\n",
        "== = eq\\\n",
        "\\>= = ge\\\n",
        "<= = le\\\n",
        "\\> = gt\\\n",
        "< = lt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNsmUKJ85pvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "b477c657-7d31-413b-b6b1-52cabd1d1102"
      },
      "source": [
        "a = torch.arange(12).view(3, 4)\n",
        "b = a.clone()\n",
        "a[2,2] = 0\n",
        "print(a[2,2])\n",
        "print(torch.eq(a, b))\n",
        "print(torch.equal(a, b))\n",
        "print(a == b)\n",
        "print(a <= b)\n",
        "print(torch.le(a, b))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True, False,  True]])\n",
            "False\n",
            "tensor([[ True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True, False,  True]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAVYr_BI--B9",
        "colab_type": "text"
      },
      "source": [
        "# where和gather操作\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-eQr2g2_EG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1983e194-d318-4de6-b038-f04f45dac0f9"
      },
      "source": [
        "condition = torch.tensor([[True, False, True], [True, False, False], [False, True, True]])\n",
        "x1 = torch.full([3, 3], 5).float()\n",
        "x2 = torch.full([3, 3], 2).float()\n",
        "a = torch.where(condition, x1, x2)\n",
        "print(a)\n",
        "idx = torch.tensor([[1, 2, 0], [0, 2, 1], [2, 2, 2]])\n",
        "label = torch.tensor([[4, 5, 6], [1, 2, 3], [7, 8, 9]])\n",
        "print(torch.gather(label, 1, idx))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5., 2., 5.],\n",
            "        [5., 2., 2.],\n",
            "        [2., 5., 5.]])\n",
            "tensor([[5, 6, 4],\n",
            "        [1, 3, 2],\n",
            "        [9, 9, 9]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}