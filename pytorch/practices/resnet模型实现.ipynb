{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet模型实现.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPR5k9t/EK6nMrII/IVfUWB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZinoTAT/Machine-Learning/blob/master/pytorch/practices/resnet%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-ZVnzkC5dTL",
        "colab_type": "text"
      },
      "source": [
        "自己动手写一个resnet\n",
        "![resnet](https://github.com/ZinoTAT/Machine-Learning/blob/master/images/resnet.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmexuRrDoMz9",
        "colab_type": "code",
        "outputId": "1811e2e3-9c13-4985-9662-979c6f5e33f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvtsdm74og0d",
        "colab_type": "text"
      },
      "source": [
        "为方便后续使用，封装一下接下来将要使用的3 * 3卷积和1 * 1卷积"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyPJzYQjoWDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_channels, out_channels, stride=1, padding=1):\n",
        "  return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=False) #bias设置为false是为了在有bn层的情况下节省参数\n",
        "def conv1x1(in_channels, out_channels, stride=1, padding=0):\n",
        "  return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=padding, bias=False) #bias设置为false是为了在有bn层的情况下节省参数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc6M1qiXnRVF",
        "colab_type": "text"
      },
      "source": [
        "50层以下使用的BasicBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMc-fuPeq3v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, stride=1, downsample=None, norm_layer=None):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "    self.bn1 = norm_layer(out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = conv3x3(out_channels, out_channels)\n",
        "    self.bn2 = norm_layer(out_channels)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(identity) #如果输入的x和输出的x存在维度变换，则要先将维度进行统一再相加\n",
        "\n",
        "    x += identity\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP21_fvrnY9V",
        "colab_type": "text"
      },
      "source": [
        "50层以上使用的BottleBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSHKnC3Hxv4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BottleBlock(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_channels, channels, stride=1, downsample=None, norm_layer=None):\n",
        "    super(BottleBlock, self).__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    self.conv1 = conv1x1(in_channels, channels)\n",
        "    self.bn1 = norm_layer(channels)\n",
        "    self.conv2 = conv3x3(channels, channels, stride=stride)\n",
        "    self.bn2 = norm_layer(channels)\n",
        "    self.conv3 = conv1x1(channels, channels * self.expansion)\n",
        "    self.bn3 = norm_layer(channels * self.expansion)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    \n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(identity)\n",
        "    \n",
        "    x += identity\n",
        "    x = self.relu(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5t2jRsAoISE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, name, block, layers, num_class=1000, norm_layer=None):\n",
        "    super(ResNet, self).__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    self._norm_layer = norm_layer\n",
        "\n",
        "    self.in_channels = 64\n",
        "    self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = norm_layer(self.in_channels)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "    self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "    self.AdaptiveAvgPool2d = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_class)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.name = name\n",
        "  \n",
        "  def _make_layer(self, block, channels, blocks, stride=1):\n",
        "    \n",
        "    downsample = None\n",
        "    norm_layer = self._norm_layer\n",
        "    if stride != 1 or self.in_channels != channels * block.expansion:\n",
        "      downsample = nn.Sequential(\n",
        "          conv1x1(in_channels=self.in_channels, out_channels=channels * block.expansion, stride=stride),\n",
        "          norm_layer(channels * block.expansion)\n",
        "      )\n",
        "    layers = []\n",
        "    layers.append(block(self.in_channels, channels, stride, downsample, norm_layer))\n",
        "    self.in_channels = channels * block.expansion\n",
        "    for _ in range(1, blocks):\n",
        "      layers.append(block(self.in_channels, channels,norm_layer=norm_layer))\n",
        "    return nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    x = self.AdaptiveAvgPool2d(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPIyfXy0fufu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4244d2c9-bbbe-4ea0-9696-1f91b7c9a66b"
      },
      "source": [
        "def resnet18():\n",
        "  return ResNet('resnet18', BottleBlock, [2, 2, 2, 2])\n",
        "def resnet50():\n",
        "  return ResNet('resnet50', BottleBlock, [3, 4, 6, 3])\n",
        "rn18 = resnet18()\n",
        "rn50 = resnet50()\n",
        "x = torch.randn([1, 3, 224, 224])\n",
        "y1 = rn18.forward(x)\n",
        "y2 = rn50.forward(x)\n",
        "print(y1.shape, y2.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000]) torch.Size([1, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}