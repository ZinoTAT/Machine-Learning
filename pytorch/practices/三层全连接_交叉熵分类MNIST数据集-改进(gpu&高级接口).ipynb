{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "三层全连接-交叉熵分类MNIST数据集.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnB/+0IOXnEFz3CdkAk/kh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZinoTAT/Machine-Learning/blob/master/pytorch/practices/%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5_%E4%BA%A4%E5%8F%89%E7%86%B5%E5%88%86%E7%B1%BBMNIST%E6%95%B0%E6%8D%AE%E9%9B%86-%E6%94%B9%E8%BF%9B(gpu%26%E9%AB%98%E7%BA%A7%E6%8E%A5%E5%8F%A3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ULiqCQ60xr",
        "colab_type": "text"
      },
      "source": [
        "使用更高级的接口完成了模型，并使用gpu运算，比较遗憾的是移到gpu上之后总体的速度并没有提升，我猜测的原因是数据的运算量本身不大，拷贝到gpu带来的额外时间使得运算速度上的提升被平衡了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3meSqAWKFOVp",
        "colab_type": "code",
        "outputId": "753a6ae3-166a-419b-c351-4630e25d185f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch \n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT_bUQsvKCoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 200\n",
        "learning_rate=0.01\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wK046NnKKbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])),\n",
        "    batch_size=batch_size, shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])),\n",
        "    batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCT2tFaufbn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP,self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(784, 200),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(200, 200),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(200, 10),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x =self.model(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70HgzBDevfVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4fa04d4-599d-4d56-bc0e-7ff0657e3bc9"
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gatsfGFhJGUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = MLP().to(device)\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "criteon = nn.CrossEntropyLoss().to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6SbOtPbNd3T",
        "colab_type": "code",
        "outputId": "c6f3d9ba-b973-476a-88bf-b1108314a4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data = data.reshape(-1, 28 * 28)\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    logits = net.forward(data)\n",
        "    loss = criteon(logits, target)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data = data.view(-1, 28 * 28)\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    logits = net.forward(data)\n",
        "    test_loss += criteon(logits, target).item()\n",
        "    pred = logits.data.max(1)[1]\n",
        "    correct += pred.eq(target.data).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('epoch:{}\\ntest loss={},correct:{}'.format(epoch, test_loss, float(correct) / float(len(test_loader) * test_loader.batch_size)))\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0\n",
            "test loss=0.005651641857624054,correct:0.6999\n",
            "epoch:1\n",
            "test loss=0.003436533486843109,correct:0.8103\n",
            "epoch:2\n",
            "test loss=0.0028875512778759,correct:0.8224\n",
            "epoch:3\n",
            "test loss=0.0026593067497015,correct:0.8299\n",
            "epoch:4\n",
            "test loss=0.0025175923883914947,correct:0.8349\n",
            "epoch:5\n",
            "test loss=0.002420681667327881,correct:0.8394\n",
            "epoch:6\n",
            "test loss=0.0023372362792491914,correct:0.8426\n",
            "epoch:7\n",
            "test loss=0.0022809230625629425,correct:0.8457\n",
            "epoch:8\n",
            "test loss=0.0022296066522598267,correct:0.8491\n",
            "epoch:9\n",
            "test loss=0.0021802582621574403,correct:0.8504\n",
            "epoch:10\n",
            "test loss=0.0021431215018033983,correct:0.8526\n",
            "epoch:11\n",
            "test loss=0.0021035252839326857,correct:0.8537\n",
            "epoch:12\n",
            "test loss=0.00207072291970253,correct:0.8558\n",
            "epoch:13\n",
            "test loss=0.0020416665971279145,correct:0.8574\n",
            "epoch:14\n",
            "test loss=0.0020065725654363634,correct:0.8595\n",
            "epoch:15\n",
            "test loss=0.0019814818143844603,correct:0.8598\n",
            "epoch:16\n",
            "test loss=0.0019574264973402024,correct:0.8602\n",
            "epoch:17\n",
            "test loss=0.0019278084456920623,correct:0.8624\n",
            "epoch:18\n",
            "test loss=0.0019030356138944626,correct:0.8651\n",
            "epoch:19\n",
            "test loss=0.0018765995025634766,correct:0.8658\n",
            "epoch:20\n",
            "test loss=0.0018561167135834693,correct:0.8666\n",
            "epoch:21\n",
            "test loss=0.0018355869844555856,correct:0.8676\n",
            "epoch:22\n",
            "test loss=0.0018215400457382203,correct:0.8677\n",
            "epoch:23\n",
            "test loss=0.001802060341835022,correct:0.8694\n",
            "epoch:24\n",
            "test loss=0.0017792078897356986,correct:0.8707\n",
            "epoch:25\n",
            "test loss=0.0017663245037198066,correct:0.8712\n",
            "epoch:26\n",
            "test loss=0.0017537890300154686,correct:0.8714\n",
            "epoch:27\n",
            "test loss=0.0017359459042549134,correct:0.8734\n",
            "epoch:28\n",
            "test loss=0.0017228756174445152,correct:0.8734\n",
            "epoch:29\n",
            "test loss=0.001717019633948803,correct:0.8735\n",
            "epoch:30\n",
            "test loss=0.0017024914041161537,correct:0.8745\n",
            "epoch:31\n",
            "test loss=0.00169076017588377,correct:0.8749\n",
            "epoch:32\n",
            "test loss=0.001681119552254677,correct:0.8752\n",
            "epoch:33\n",
            "test loss=0.0016651236429810524,correct:0.876\n",
            "epoch:34\n",
            "test loss=0.001659688249230385,correct:0.8759\n",
            "epoch:35\n",
            "test loss=0.0016504779174923896,correct:0.8767\n",
            "epoch:36\n",
            "test loss=0.0016379452154040336,correct:0.8767\n",
            "epoch:37\n",
            "test loss=0.0016348305225372315,correct:0.8772\n",
            "epoch:38\n",
            "test loss=0.0016223296746611594,correct:0.8778\n",
            "epoch:39\n",
            "test loss=0.0016151757448911667,correct:0.877\n",
            "epoch:40\n",
            "test loss=0.0016093649253249168,correct:0.878\n",
            "epoch:41\n",
            "test loss=0.001601968738436699,correct:0.8779\n",
            "epoch:42\n",
            "test loss=0.001599532337486744,correct:0.8782\n",
            "epoch:43\n",
            "test loss=0.001592589557170868,correct:0.8777\n",
            "epoch:44\n",
            "test loss=0.001582344835996628,correct:0.8798\n",
            "epoch:45\n",
            "test loss=0.001580693082511425,correct:0.8791\n",
            "epoch:46\n",
            "test loss=0.0015732738196849822,correct:0.8792\n",
            "epoch:47\n",
            "test loss=0.0015680509701371194,correct:0.8792\n",
            "epoch:48\n",
            "test loss=0.0015640928328037262,correct:0.8806\n",
            "epoch:49\n",
            "test loss=0.0015579062774777413,correct:0.8798\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}